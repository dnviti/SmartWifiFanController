name: AI Code Analysis (ChatGPT - Individual Issues)
on:
  pull_request:
    paths: # Specify paths to trigger the workflow on PRs
      - 'src/**.cpp'
      - 'src/**.h'
      - 'test/**.cpp'
      # Add other relevant file types and paths
  workflow_dispatch: # Allows manual triggering

jobs:
  analyze-code:
    runs-on: ubuntu-latest
    permissions:
      contents: read          # To checkout the repository
      pull-requests: read    # To read PR details if needed (e.g., PR number for context)
      issues: write          # REQUIRED to create issues

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Fetches all history for accurate diffs

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10' # Or your preferred Python version

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install openai
          pip install requests # For creating GitHub issues

      - name: Get changed files
        id: changed_files
        run: |
          echo "Determining files to analyze..."
          if [ "${{ github.event_name }}" == "pull_request" ]; then
            MERGE_BASE=$(git merge-base ${{ github.event.pull_request.base.sha }} HEAD)
            FILES=$(git diff --name-only $MERGE_BASE HEAD | grep -E '\.(cpp|h)$' | tr '\n' ' ')
          else # For workflow_dispatch or other events, analyze all relevant files
            FILES=$(find . -type f \( -name "*.cpp" -o -name "*.h" \) -not -path "./.git/*" -not -path "./build/*" | tr '\n' ' ')
          fi
          if [ -z "$FILES" ]; then
            echo "No relevant files found to analyze."
            echo "files_to_analyze=''" >> $GITHUB_OUTPUT
          else
            echo "Files to analyze: $FILES"
            echo "files_to_analyze=$FILES" >> $GITHUB_OUTPUT
          fi
        shell: bash

      - name: Run AI Code Analysis Script (ChatGPT - Individual Issues)
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} 
          REPO_NAME: ${{ github.repository }}
          PR_NUMBER: ${{ github.event.pull_request.number }}
          # You can set a default model, or allow override via secrets/env vars
          OPENAI_MODEL_NAME_OVERRIDE: ${{ secrets.OPENAI_MODEL_NAME_OVERRIDE }}
        run: |
          import os
          import time
          import random
          import json
          import openai
          import requests # For GitHub API calls

          # --- Configuration ---
          MAX_RETRIES = 5
          INITIAL_BACKOFF = 5  # Increased initial backoff
          INTER_FILE_DELAY = 3 # Increased delay between files
          OPENAI_MODEL_NAME = os.getenv('OPENAI_MODEL_NAME_OVERRIDE', 'gpt-4o-mini')

          OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
          if not OPENAI_API_KEY:
              print("Error: OPENAI_API_KEY not found in environment variables.")
              exit(1)

          try:
            client = openai.OpenAI(api_key=OPENAI_API_KEY)
            print(f"Successfully configured OpenAI client for model: {OPENAI_MODEL_NAME}")
          except Exception as e:
            print(f"Error configuring OpenAI client: {e}")
            exit(1)

          def call_openai_for_issues(file_path, file_content):
              """
              Calls OpenAI API, expecting a JSON array of issue objects.
              Each issue object should have 'title', 'description', and 'category'.
              """
              print(f"Requesting AI analysis for issues in {file_path} using {OPENAI_MODEL_NAME}...")
              retries = 0
              backoff_time = INITIAL_BACKOFF
              
              system_message = (
                  "You are an expert C++ code reviewer. Your task is to analyze the provided code snippet "
                  "and identify distinct issues. These issues can be bugs, areas for improvement/refactoring, "
                  "or suggestions for new features directly related to THIS code snippet. "
                  "For each distinct issue you identify, provide a JSON object with the following fields:\n"
                  "- \"title\": A concise title for a GitHub issue (max 80 characters).\n"
                  "- \"description\": A detailed Markdown-formatted description of the issue. Explain the problem or "
                  "suggestion, why it's relevant, and if possible, suggest a fix or implementation idea. "
                  "Reference the file path '{file_path}' in your description.\n"
                  "- \"category\": Classify the issue. Choose ONLY from: \"bug\", \"enhancement\", \"refactor\", \"documentation\", \"feature_suggestion\".\n"
                  "Return a JSON array containing these issue objects. If no issues are found for this specific file, return an empty JSON array []."
              )
              user_prompt = (
                  f"Analyze the following C++ code from the file '{file_path}'. "
                  "Focus only on issues present in or directly suggested by THIS code. "
                  "Remember to provide your response strictly as a JSON array of issue objects, or an empty array if no issues are found.\n\n"
                  f"File Path: {file_path}\n"
                  "```cpp\n"
                  f"{file_content}\n"
                  "```\n"
                  "JSON Array of Issues:"
              )

              while retries < MAX_RETRIES:
                  try:
                      response = client.chat.completions.create(
                          model=OPENAI_MODEL_NAME,
                          messages=[
                              {"role": "system", "content": system_message},
                              {"role": "user", "content": user_prompt}
                          ],
                          response_format={"type": "json_object"}, # Request JSON output if model supports it
                          # temperature parameter removed as per previous error with gpt-4o-mini
                      )
                      response_content = response.choices[0].message.content.strip()
                      
                      # The AI might wrap the JSON array in a larger JSON object if response_format is used.
                      # Or it might return a string that needs to be parsed.
                      # Attempt to parse the response as JSON.
                      try:
                          # Check if the response is already a JSON object containing the array
                          # (common when using response_format={"type": "json_object"})
                          parsed_response = json.loads(response_content)
                          # Look for a key that might contain the array, or assume the root is the array
                          # This part might need adjustment based on how your specific model version
                          # structures its JSON output when `response_format={"type": "json_object"}` is used.
                          # Common patterns: "issues", "suggestions", or the root itself.
                          # For now, let's assume the AI is instructed to return an array directly,
                          # or it's under a common key like "issues".
                          if isinstance(parsed_response, list):
                              issues = parsed_response
                          elif isinstance(parsed_response, dict) and "issues" in parsed_response and isinstance(parsed_response["issues"], list):
                              issues = parsed_response["issues"]
                          elif isinstance(parsed_response, dict) and "suggestions" in parsed_response and isinstance(parsed_response["suggestions"], list):
                              issues = parsed_response["suggestions"]
                          else:
                              # If the response is a dict but doesn't have an obvious key for the list,
                              # and the prompt specifically asked for an array, this is unexpected.
                              # However, if the prompt was to fill a schema, the root dict might be the "object"
                              # and we need to find the array within it.
                              # For this prompt, we expect a direct array or an object with a known key.
                              # Falling back to trying to parse the raw string if the structure isn't immediately obvious.
                              print(f"AI returned a JSON object, but expected an array or a dict with a known key for issues. Content: {response_content[:200]}...")
                              # This fallback might be risky if the AI doesn't strictly follow the "array" instruction.
                              # For now, we'll assume the direct array or a simple dict wrapper.
                              # If the AI is well-behaved with the prompt, this part might not be hit often.
                              issues = json.loads(response_content) if isinstance(json.loads(response_content), list) else []


                          print(f"Successfully received and parsed AI analysis for {file_path} on attempt {retries + 1}. Found {len(issues)} potential issues.")
                          return issues
                      except json.JSONDecodeError:
                          print(f"Warning: AI response for {file_path} was not valid JSON on attempt {retries + 1}. Response: {response_content[:500]}...")
                          # If JSON parsing fails, we can't proceed with creating structured issues.
                          # We could try to extract text, but it defeats the purpose of structured output.
                          # For now, we'll retry, hoping for a valid JSON next time.
                          # If all retries fail, this will eventually fall through to the APIError handling or general Exception.
                          # Consider returning a special marker or logging this as a failure for this file.
                          if retries >= MAX_RETRIES -1: # Last attempt failed parsing
                             return [{"title": f"AI Analysis Error: Non-JSON Response for {file_path}", 
                                      "description": f"The AI's response for `{file_path}` was not valid JSON and could not be parsed after {MAX_RETRIES} attempts.\n\nRaw response snippet:\n```\n{response_content[:1000]}\n```",
                                      "category": "bug", "file_path": file_path}] # Create an issue about the parsing failure
                  
                  except openai.APIError as e:
                      error_str = str(e).lower()
                      if e.status_code == 400 and e.body and 'param' in e.body and e.body['param'] == 'temperature' and 'unsupported_value' in e.body.get('code',''):
                          print(f"OpenAI API error for {file_path}: Model '{OPENAI_MODEL_NAME}' does not support the specified temperature or temperature setting. Error: {e.body.get('message')}")
                          return [{"title": f"AI Model Config Error for {file_path}", "description": f"Analysis skipped for `{file_path}`: Model '{OPENAI_MODEL_NAME}' does not support current temperature settings. Error: {e.body.get('message')}", "category": "bug", "file_path": file_path}]

                      if e.status_code == 429 or "rate limit" in error_str or "too many requests" in error_str:
                          retries += 1
                          if retries >= MAX_RETRIES:
                              print(f"Max retries reached for {file_path}. Error: {e}")
                              return None # Indicate failure after retries
                          
                          retry_after_header = e.headers.get("retry-after")
                          wait_time = backoff_time
                          if retry_after_header:
                              try:
                                  wait_time = int(retry_after_header) + random.uniform(0, 1)
                                  print(f"OpenAI API rate limit for {file_path}. Retrying after {wait_time:.2f}s (from header). Error: {e}")
                              except ValueError:
                                  print(f"OpenAI API rate limit for {file_path}. Invalid retry-after header. Using exponential backoff: {wait_time:.2f}s. Error: {e}")
                                  backoff_time *= 2
                          else:
                              print(f"OpenAI API rate limit for {file_path}. Retrying in {wait_time:.2f}s. Error: {e}")
                              backoff_time *= 2
                          time.sleep(wait_time)
                      elif e.status_code >= 500: # Server-side errors
                          retries += 1
                          if retries >= MAX_RETRIES: return None
                          wait_time = backoff_time + random.uniform(0, 1.5)
                          print(f"OpenAI API server error for {file_path}. Retrying in {wait_time:.2f}s. Error: {e}")
                          time.sleep(wait_time)
                          backoff_time *= 1.5
                      else:
                          print(f"Unexpected OpenAI API error for {file_path}: {e}")
                          if e.body: print(f"Error details: {e.body}")
                          return None # Non-retryable or unknown API error
                  except Exception as e:
                      print(f"General error calling OpenAI for {file_path}: {e}")
                      retries += 1
                      if retries >= MAX_RETRIES: return None
                      time.sleep(backoff_time + random.uniform(0,1.5))
                      backoff_time *= 2
              return None # All retries failed

          def create_github_issue(title, body, labels=None):
              github_token = os.getenv('GITHUB_TOKEN')
              repo_name = os.getenv('REPO_NAME')
              if not github_token or not repo_name:
                  print("Error: GITHUB_TOKEN or REPO_NAME not set. Cannot create issue.")
                  print(f"Skipped Issue Title: {title}\nBody:\n{body}\nLabels: {labels}")
                  return False

              api_url = f"https://api.github.com/repos/{repo_name}/issues"
              headers = {
                  "Authorization": f"token {github_token}",
                  "Accept": "application/vnd.github.v3+json",
                  "X-GitHub-Api-Version": "2022-11-28"
              }
              data = {"title": title, "body": body}
              if labels:
                  data["labels"] = labels
              
              try:
                  response = requests.post(api_url, json=data, headers=headers)
                  response.raise_for_status() 
                  print(f"Successfully created GitHub issue: '{title}'. URL: {response.json().get('html_url')}")
                  return True
              except requests.exceptions.RequestException as e:
                  print(f"Failed to create GitHub issue '{title}'. Error: {e}")
                  if response is not None:
                      print(f"Response status: {response.status_code}, Response text: {response.text}")
                  return False
              except Exception as e:
                  print(f"An unexpected error occurred during GitHub issue creation: {e}")
                  return False

          files_to_analyze_str = os.getenv('FILES_TO_ANALYZE', "${{ steps.changed_files.outputs.files_to_analyze }}")
          
          if not files_to_analyze_str or not files_to_analyze_str.strip():
              print("No files to analyze.")
              exit(0)
          
          files_to_analyze = [f.strip() for f in files_to_analyze_str.strip().split(' ') if f.strip()]
          
          if not files_to_analyze:
              print("No valid file paths to analyze.")
              exit(0)
              
          print(f"Files queued for analysis: {files_to_analyze}")
          total_issues_created = 0

          for i, file_path in enumerate(files_to_analyze):
              print(f"\nProcessing file {i+1}/{len(files_to_analyze)}: {file_path}")
              try:
                  with open(file_path, 'r', encoding='utf-8') as f:
                      file_content = f.read()
                  
                  if not file_content.strip():
                      print(f"Skipping empty file: {file_path}")
                      continue

                  # Get a list of issue objects from the AI
                  identified_issues = call_openai_for_issues(file_path, file_content)
                  
                  if identified_issues is None:
                      print(f"AI analysis failed for {file_path} after retries.")
                  elif not identified_issues: # Empty list means AI found no issues
                      print(f"AI found no specific issues to report for {file_path}.")
                  else:
                      print(f"AI identified {len(identified_issues)} potential issues for {file_path}.")
                      for issue_data in identified_issues:
                          if not isinstance(issue_data, dict) or not all(k in issue_data for k in ["title", "description", "category"]):
                              print(f"Warning: Invalid issue format received from AI for {file_path}. Skipping: {issue_data}")
                              continue

                          title = f"AI Suggestion for `{issue_data.get('file_path', file_path)}`: {issue_data['title']}"
                          # Add PR context to description if available
                          pr_number_env = os.getenv('PR_NUMBER')
                          pr_context = f"\n\n_Context: Analysis triggered by PR #{pr_number_env}_" if pr_number_env else ""
                          body = f"{issue_data['description']}{pr_context}"
                          
                          category = issue_data['category'].lower()
                          labels = ["AI Suggested"]
                          if category == "bug":
                              labels.append("bug")
                          elif category == "enhancement":
                              labels.append("enhancement")
                          elif category == "refactor":
                              labels.append("refactor")
                          elif category == "documentation":
                              labels.append("documentation")
                          elif category == "feature_suggestion":
                              labels.append("feature request")
                          else:
                              labels.append("ai-misc") # Default for unknown categories

                          if create_github_issue(title, body, labels):
                              total_issues_created += 1
                          time.sleep(1) # Small delay between creating issues to be kind to GitHub API

              except FileNotFoundError:
                  print(f"Error: File not found - {file_path}")
              except Exception as e:
                  print(f"Error processing file {file_path}: {e}")
              
              if len(files_to_analyze) > 1 and i < len(files_to_analyze) - 1:
                  print(f"Waiting for {INTER_FILE_DELAY} seconds before processing the next file...")
                  time.sleep(INTER_FILE_DELAY)
          
          print(f"\nAI code analysis (OpenAI) process complete. Total GitHub issues created: {total_issues_created}")

        shell: python
