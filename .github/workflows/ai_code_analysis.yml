name: AI Code Analysis (ChatGPT - Individual Issues)
on:
  pull_request:
    paths: # Specify paths to trigger the workflow on PRs
      - 'src/**.cpp'
      - 'src/**.h'
      - 'test/**.cpp'
      # Add other relevant file types and paths
  workflow_dispatch: # Allows manual triggering
    inputs:
      custom_openai_model:
        description: 'OpenAI Model to use (e.g., o4-mini, gpt-4o-mini). Leave empty for script default.'
        required: false
        default: '' # Default to empty, script will use its own default

jobs:
  analyze-code:
    runs-on: ubuntu-latest
    permissions:
      contents: read          # To checkout the repository
      pull-requests: read    # To read PR details if needed (e.g., PR number for context)
      issues: write          # REQUIRED to create issues

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Fetches all history for accurate diffs

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10' # Or your preferred Python version

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install openai
          pip install requests # For creating GitHub issues

      - name: Get changed files
        id: changed_files
        run: |
          echo "Determining files to analyze..."
          if [ "${{ github.event_name }}" == "pull_request" ]; then
            MERGE_BASE=$(git merge-base ${{ github.event.pull_request.base.sha }} HEAD)
            # Ensure paths are relative by nature of git diff
            FILES=$(git diff --name-only --relative $MERGE_BASE HEAD | grep -E '\.(cpp|h|c|hpp|cc|hh|cxx|hxx)$' | tr '\n' ' ')
          else 
            echo "Triggered by workflow_dispatch or other event. Python script will handle file discovery if FILES_TO_ANALYZE='*'."
            FILES="*" # Signal to Python script to find all files
          fi
          if [ -z "$FILES" ]; then
            echo "No relevant files found by git diff or FILES_TO_ANALYZE not set to '*' for full scan."
            echo "files_to_analyze=''" >> $GITHUB_OUTPUT
          else
            echo "Files to analyze (or '*' for full scan): $FILES"
            echo "files_to_analyze=$FILES" >> $GITHUB_OUTPUT
          fi
        shell: bash

      - name: Run AI Code Analysis Script (ChatGPT - Individual Issues)
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} 
          REPO_NAME: ${{ github.repository }}
          PR_NUMBER: ${{ github.event.pull_request.number }}
          OPENAI_MODEL_NAME_OVERRIDE: ${{ github.event.inputs.custom_openai_model || '' }}
          FILES_TO_ANALYZE: "${{ steps.changed_files.outputs.files_to_analyze }}"
          GITHUB_WORKSPACE: ${{ github.workspace }} # Pass workspace path to script
        run: |
          import os
          import time
          import random
          import json
          import openai
          import requests # For GitHub API calls

          # --- Configuration ---
          MAX_RETRIES = 5
          INITIAL_BACKOFF = 5
          INTER_FILE_DELAY = 3
          DEFAULT_OPENAI_MODEL_NAME = '4o-mini' 
          OPENAI_MODEL_NAME = os.getenv('OPENAI_MODEL_NAME_OVERRIDE', DEFAULT_OPENAI_MODEL_NAME)
          if not OPENAI_MODEL_NAME.strip(): 
              OPENAI_MODEL_NAME = DEFAULT_OPENAI_MODEL_NAME
              
          RELEVANT_EXTENSIONS = ('.cpp', '.h', '.c', '.hpp', '.cc', '.hh', '.cxx', '.hxx')
          EXCLUDE_DIRS = ['.git', '.github', 'build', 'dist', 'venv', '.venv', 'node_modules', '__pycache__', 'docs/build']
          EXCLUDE_FILES = ['LICENSE', 'LICENSE.md', 'CONTRIBUTING.md']
          GITHUB_WORKSPACE_PATH = os.getenv('GITHUB_WORKSPACE', os.getcwd()) # Get workspace path

          OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
          if not OPENAI_API_KEY:
              print("Error: OPENAI_API_KEY not found in environment variables.")
              exit(1)

          print(f"Initializing AI Code Analysis Script. Attempting to use OpenAI model: '{OPENAI_MODEL_NAME}'")

          try:
            client = openai.OpenAI(api_key=OPENAI_API_KEY)
            print(f"Successfully configured OpenAI client.") 
          except Exception as e:
            print(f"Error configuring OpenAI client: {e}")
            exit(1)

          def get_relative_path(abs_path):
              # Ensure paths are relative to the workspace root
              # os.path.relpath is safer than string stripping if abs_path is already relative
              try:
                  # First, ensure abs_path is indeed absolute or make it so if it's already project-relative
                  if not os.path.isabs(abs_path):
                      abs_path = os.path.join(GITHUB_WORKSPACE_PATH, abs_path)
                  
                  rel_path = os.path.relpath(abs_path, GITHUB_WORKSPACE_PATH)
                  # If relpath returns something starting with '..' it means it's outside workspace,
                  # which shouldn't happen for files found by walking "." or from git diff --relative
                  if rel_path.startswith(".."):
                      return abs_path # Fallback to original if relpath goes outside
                  return rel_path
              except ValueError: # Can happen if paths are on different drives (not applicable here)
                  return abs_path # Fallback


          def call_openai_for_issues(file_path_for_ai, file_content):
              """
              Calls OpenAI API, expecting a JSON array of issue objects.
              file_path_for_ai should be the relative path for use in prompts.
              """
              print(f"Requesting AI analysis for issues in {file_path_for_ai} using {OPENAI_MODEL_NAME}...")
              retries = 0
              backoff_time = INITIAL_BACKOFF
              
              system_message = (
                  "You are an expert C++ code reviewer. Your task is to analyze the provided code snippet "
                  "and identify distinct issues. These issues can be bugs, areas for improvement/refactoring, "
                  "or suggestions for new features directly related to THIS code snippet. "
                  "For each distinct issue you identify, provide a JSON object with the following fields:\n"
                  "- \"title\": A concise title for a GitHub issue (max 80 characters).\n"
                  "- \"description\": A detailed Markdown-formatted description of the issue. Explain the problem or "
                  "suggestion, why it's relevant, and if possible, suggest a fix or implementation idea. "
                  f"Reference the file path '{file_path_for_ai}' in your description.\n" # Use relative path in prompt
                  "- \"category\": Classify the issue. Choose ONLY from: \"bug\", \"enhancement\", \"refactor\", \"documentation\", \"feature_suggestion\".\n"
                  "Return a JSON array containing these issue objects. If no issues are found for this specific file, return an empty JSON array []."
              )
              user_prompt = (
                  f"Analyze the following C++ code from the file '{file_path_for_ai}'. " # Use relative path
                  "Focus only on issues present in or directly suggested by THIS code. "
                  "Remember to provide your response strictly as a JSON array of issue objects, or an empty array if no issues are found.\n\n"
                  f"File Path: {file_path_for_ai}\n" # Use relative path
                  "```cpp\n" 
                  f"{file_content}\n"
                  "```\n"
                  "JSON Array of Issues:"
              )

              while retries < MAX_RETRIES:
                  try:
                      response = client.chat.completions.create(
                          model=OPENAI_MODEL_NAME,
                          messages=[
                              {"role": "system", "content": system_message},
                              {"role": "user", "content": user_prompt}
                          ],
                          response_format={"type": "json_object"}, 
                      )
                      response_content = response.choices[0].message.content.strip()
                      
                      try:
                          parsed_response = json.loads(response_content)
                          if isinstance(parsed_response, list):
                              issues = parsed_response
                          elif isinstance(parsed_response, dict) and "issues" in parsed_response and isinstance(parsed_response["issues"], list):
                              issues = parsed_response["issues"]
                          elif isinstance(parsed_response, dict) and "suggestions" in parsed_response and isinstance(parsed_response["suggestions"], list):
                              issues = parsed_response["suggestions"]
                          else:
                              print(f"AI returned a JSON object, but expected an array or a dict with a known key for issues. Content: {response_content[:200]}...")
                              try:
                                  potential_list = json.loads(response_content)
                                  if isinstance(potential_list, list):
                                      issues = potential_list
                                  else:
                                      issues = [] 
                              except json.JSONDecodeError:
                                   issues = [] 

                          print(f"Successfully received and parsed AI analysis for {file_path_for_ai} on attempt {retries + 1}. Found {len(issues)} potential issues.")
                          return issues
                      except json.JSONDecodeError:
                          print(f"Warning: AI response for {file_path_for_ai} was not valid JSON on attempt {retries + 1}. Response: {response_content[:500]}...")
                          if retries >= MAX_RETRIES -1:
                            return [{"title": f"AI Analysis Error: Non-JSON Response for {file_path_for_ai}", 
                                      "description": f"The AI's response for `{file_path_for_ai}` was not valid JSON and could not be parsed after {MAX_RETRIES} attempts.\n\nRaw response snippet:\n```\n{response_content[:1000]}\n```",
                                      "category": "internal_error", "file_path": file_path_for_ai}] 
                  
                  except openai.APIError as e:
                      error_str = str(e).lower()
                      if hasattr(e, 'code') and e.code == 'model_not_found':
                          print(f"OpenAI API error for {file_path_for_ai}: Model '{OPENAI_MODEL_NAME}' not found or access denied. Error: {e}")
                          return [{"title": f"AI Model Not Found: {OPENAI_MODEL_NAME}", "description": f"Analysis skipped for `{file_path_for_ai}`: The OpenAI model '{OPENAI_MODEL_NAME}' was not found or your API key does not have access to it. Please verify the model name and your API key permissions. Error details: {e}", "category": "configuration_error", "file_path": file_path_for_ai}]

                      if e.status_code == 400 and hasattr(e, 'body') and e.body and 'param' in e.body and e.body.get('param') == 'temperature' and 'unsupported_value' in e.body.get('code',''):
                          print(f"OpenAI API error for {file_path_for_ai}: Model '{OPENAI_MODEL_NAME}' does not support the specified temperature or temperature setting. Error: {e.body.get('message')}")
                          return [{"title": f"AI Model Config Error for {file_path_for_ai}", "description": f"Analysis skipped for `{file_path_for_ai}`: Model '{OPENAI_MODEL_NAME}' does not support current temperature settings. Error: {e.body.get('message')}", "category": "configuration_error", "file_path": file_path_for_ai}]

                      if e.status_code == 429 or "rate limit" in error_str or "too many requests" in error_str:
                          retries += 1
                          if retries >= MAX_RETRIES:
                              print(f"Max retries reached for {file_path_for_ai}. Error: {e}")
                              return None # Or return an error issue object
                          
                          retry_after_header = e.headers.get("retry-after") if hasattr(e, 'headers') else None
                          wait_time = backoff_time
                          if retry_after_header:
                              try:
                                  wait_time = int(retry_after_header) + random.uniform(0, 1)
                                  print(f"OpenAI API rate limit for {file_path_for_ai}. Retrying after {wait_time:.2f}s (from header). Error: {e}")
                              except ValueError:
                                  print(f"OpenAI API rate limit for {file_path_for_ai}. Invalid retry-after header. Using exponential backoff: {wait_time:.2f}s. Error: {e}")
                                  backoff_time *= 2
                          else:
                              print(f"OpenAI API rate limit for {file_path_for_ai}. Retrying in {wait_time:.2f}s. Error: {e}")
                              backoff_time *= 2
                          time.sleep(wait_time)
                      elif e.status_code >= 500: # Server-side errors
                          retries += 1
                          if retries >= MAX_RETRIES: return None
                          wait_time = backoff_time + random.uniform(0, 1.5)
                          print(f"OpenAI API server error for {file_path_for_ai}. Retrying in {wait_time:.2f}s. Error: {e}")
                          time.sleep(wait_time)
                          backoff_time *= 1.5 # Increase backoff more aggressively for server errors
                      else: # Other client-side errors (4xx not caught above)
                          print(f"Unexpected OpenAI API error for {file_path_for_ai}: {e}")
                          if hasattr(e, 'body') and e.body: print(f"Error details: {e.body}")
                          return None # Or an error issue object
                  except Exception as e: # Catch other unexpected errors
                      print(f"General error calling OpenAI for {file_path_for_ai}: {e}")
                      retries += 1
                      if retries >= MAX_RETRIES: return None
                      time.sleep(backoff_time + random.uniform(0,1.5))
                      backoff_time *= 2
              return None # Should not be reached if retries are handled correctly

          def create_github_issue(title, body, labels=None):
              github_token = os.getenv('GITHUB_TOKEN')
              repo_name = os.getenv('REPO_NAME')
              if not github_token or not repo_name:
                  print("Error: GITHUB_TOKEN or REPO_NAME not set. Cannot create issue.")
                  print(f"Skipped Issue Title: {title}\nBody:\n{body}\nLabels: {labels}")
                  return False

              api_url = f"https://api.github.com/repos/{repo_name}/issues"
              headers = {
                  "Authorization": f"token {github_token}",
                  "Accept": "application/vnd.github.v3+json",
                  "X-GitHub-Api-Version": "2022-11-28"
              }
              data = {"title": title, "body": body}
              if labels:
                  data["labels"] = labels
              
              response = None 
              try:
                  response = requests.post(api_url, json=data, headers=headers)
                  response.raise_for_status() 
                  print(f"Successfully created GitHub issue: '{title}'. URL: {response.json().get('html_url')}")
                  return True
              except requests.exceptions.RequestException as e:
                  print(f"Failed to create GitHub issue '{title}'. Error: {e}")
                  if response is not None:
                      print(f"Response status: {response.status_code}, Response text: {response.text}")
                  return False
              except Exception as e:
                  print(f"An unexpected error occurred during GitHub issue creation: {e}")
                  return False

          def get_all_repo_files(root_dir=".", extensions=RELEVANT_EXTENSIONS, exclude_dirs=EXCLUDE_DIRS, exclude_files=EXCLUDE_FILES):
              repo_files = []
              abs_exclude_dirs = [os.path.abspath(os.path.join(root_dir, d)) for d in exclude_dirs]
              for dirpath, dirnames, filenames in os.walk(root_dir):
                  # Modify dirnames in-place to exclude directories
                  dirnames[:] = [d for d in dirnames if os.path.abspath(os.path.join(dirpath, d)) not in abs_exclude_dirs and not d.startswith('.')]
                  for filename in filenames:
                      # Check extensions first
                      if any(filename.lower().endswith(ext.replace('*','')) for ext in extensions if ext.startswith('*.')): # crude way to handle simple wildcards
                          if filename.lower() not in [ef.lower() for ef in exclude_files]:
                              full_path = os.path.join(dirpath, filename)
                              # Make path relative to root_dir (which is workspace root)
                              relative_path = os.path.relpath(full_path, root_dir)
                              repo_files.append(relative_path)
              return repo_files

          def main():
              print(f"Initializing AI Code Analysis Script. Attempting to use OpenAI model: '{OPENAI_MODEL_NAME}'")

              files_to_analyze_input = os.getenv('FILES_TO_ANALYZE')
              files_to_analyze_paths = [] # This will store relative paths

              if files_to_analyze_input == "*":
                  print("FILES_TO_ANALYZE is '*', scanning repository for relevant files...")
                  # GITHUB_WORKSPACE_PATH is already the current working directory for the script
                  files_to_analyze_paths = get_all_repo_files(root_dir=".")
                  if not files_to_analyze_paths:
                      print(f"No files found with extensions {RELEVANT_EXTENSIONS} in the repository (excluding specified directories/files).")
                      sys.exit(0) # Use sys.exit(0) for clean exit
              elif files_to_analyze_input:
                  # These paths from git diff should already be relative to repo root
                  files_to_analyze_paths = [f.strip() for f in files_to_analyze_input.strip().split(' ') if f.strip()]
              else:
                  print("FILES_TO_ANALYZE environment variable not set or empty, and not '*'. Assuming no files to analyze for this run.")
                  sys.exit(0) 
              
              if not files_to_analyze_paths:
                  print("No valid file paths to analyze.")
                  sys.exit(0)
                  
              print(f"Files queued for analysis ({len(files_to_analyze_paths)}): {files_to_analyze_paths}")
              total_issues_created = 0

              for i, original_file_path in enumerate(files_to_analyze_paths):
                  # Ensure we use a clearly relative path for prompts and issue bodies
                  relative_file_path = get_relative_path(original_file_path)
                  print(f"\nProcessing file {i+1}/{len(files_to_analyze_paths)}: {relative_file_path} (original: {original_file_path})")
                  
                  try:
                      # Open file using the original path which is relative to CWD (workspace root)
                      if not os.path.exists(original_file_path):
                          print(f"Error: File not found - {original_file_path}. Skipping.")
                          continue

                      with open(original_file_path, 'r', encoding='utf-8', errors='ignore') as f:
                          file_content = f.read()
                      
                      if not file_content.strip():
                          print(f"Skipping empty file: {original_file_path}")
                          continue

                      MAX_FILE_SIZE_CHARS = 100 * 1024 
                      if len(file_content) > MAX_FILE_SIZE_CHARS:
                          print(f"Warning: File {original_file_path} is very large ({len(file_content)} chars). Truncating to {MAX_FILE_SIZE_CHARS} characters for AI analysis.")
                          file_content = file_content[:MAX_FILE_SIZE_CHARS]

                      # Pass the relative_file_path to AI for use in prompts and descriptions
                      identified_issues = call_openai_for_issues(relative_file_path, file_content)
                      
                      if identified_issues is None:
                          print(f"AI analysis failed for {relative_file_path} after retries.")
                      elif not identified_issues:
                          print(f"AI found no specific issues to report for {relative_file_path}.")
                      else:
                          print(f"AI identified {len(identified_issues)} potential issues for {relative_file_path}.")
                          for issue_data in identified_issues:
                              if not isinstance(issue_data, dict) or not all(k in issue_data for k in ["title", "description", "category"]):
                                  print(f"Warning: Invalid issue format received from AI for {relative_file_path}. Skipping: {issue_data}")
                                  continue

                              # Use relative_file_path for issue creation
                              filename_only = os.path.basename(relative_file_path) 
                              category_prefix = issue_data['category'].replace('_', ' ').title()
                              title = f"AI ({category_prefix}): {issue_data['title']} in `{filename_only}`"
                              
                              pr_number_env = os.getenv('PR_NUMBER')
                              pr_context = f"\n\n_Context: Analysis triggered by PR #{pr_number_env}_" if pr_number_env else ""
                              
                              # Ensure file_path in description is relative
                              description_with_relative_path = issue_data['description'].replace(original_file_path, relative_file_path)
                              body = f"**File:** `{relative_file_path}`\n\n{description_with_relative_path}{pr_context}"
                              
                              category = issue_data['category'].lower()
                              labels = ["AI Suggested"]
                              valid_categories_for_labels = ["bug", "enhancement", "refactor", "documentation", "feature_suggestion", "configuration_error", "internal_error"]
                              if category in valid_categories_for_labels:
                                labels.append(category.replace('_', '-')) 
                              else:
                                labels.append("ai-misc")

                              if create_github_issue(title, body, labels):
                                  total_issues_created += 1
                              time.sleep(1) # Be respectful to GitHub API

                  except FileNotFoundError:
                      print(f"Error: File not found - {original_file_path}")
                  except Exception as e:
                      print(f"Error processing file {original_file_path}: {e}")
                  
                  if len(files_to_analyze_paths) > 1 and i < len(files_to_analyze_paths) - 1:
                      print(f"Waiting for {INTER_FILE_DELAY} seconds before processing the next file...")
                      time.sleep(INTER_FILE_DELAY)
              
              print(f"\nAI code analysis (OpenAI) process complete. Total GitHub issues created: {total_issues_created}")

          if __name__ == "__main__":
              main()
        shell: python
